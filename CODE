1. Set Up the Environment
First, install the necessary libraries:

bash
Copy
Edit
pip install transformers datasets accelerate
Optionally, if you want to train on GPU and you're using a compatible system:

bash
Copy
Edit
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118




2. Load GPT-2 and Tokenizer
python
Copy
Edit
from transformers import GPT2Tokenizer, GPT2LMHeadModel

model_name = 'gpt2'  # You can also use 'gpt2-medium', 'gpt2-large'
tokenizer = GPT2Tokenizer.from_pretrained(model_name)
model = GPT2LMHeadModel.from_pretrained(model_name)



3. Prepare Your Custom Dataset
Ensure your dataset is in plain text format, or structured as lines of prompt-response or story segments. Example structure for plain text:

css
Copy
Edit
Once upon a time, in a land far away...
There lived a dragon who loved music.
Now tokenize your data:

python
Copy
Edit
from datasets import load_dataset

dataset = load_dataset('text', data_files={'train': 'your_data.txt'})

def tokenize_function(examples):
    return tokenizer(examples['text'], truncation=True, padding='max_length', max_length=512)

tokenized_datasets = dataset.map(tokenize_function, batched=True)



4. Fine-Tune the Model
Use the Trainer API from Hugging Face:

python
Copy
Edit
from transformers import Trainer, TrainingArguments

training_args = TrainingArguments(
    output_dir="./results",
    overwrite_output_dir=True,
    num_train_epochs=3,
    per_device_train_batch_size=4,
    save_steps=500,
    save_total_limit=2,
    logging_steps=100,
    logging_dir='./logs',
    prediction_loss_only=True,
)

trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=tokenized_datasets['train'],
    tokenizer=tokenizer,
)

trainer.train()




5. Save the Fine-Tuned Model
python
Copy
Edit
trainer.save_model("./fine-tuned-gpt2")
tokenizer.save_pretrained("./fine-tuned-gpt2")
6. Generate Text with Your Fine-Tuned Model
python
Copy
Edit
from transformers import pipeline

generator = pipeline('text-generation', model="./fine-tuned-gpt2", tokenizer=tokenizer)

prompt = "The castle gates creaked open, revealing"
output = generator(prompt, max_length=100, num_return_sequences=1)
print(output[0]['generated_text'])
